❓ What is the difference between the system, user, and assistant roles?

Answer:
In the OpenAI chat format, every message has a role that tells the model who is speaking and how to interpret the message.

system – Defines the model’s identity, behavior, and goals. It provides high-level instructions that the assistant must always follow. Example:
“You are an AI assistant for the project AI Agent Lab. Explain it clearly and helpfully.”

user – Represents the actual input or question from the human user. Example:
“Can you explain what Stage 1 is about?”

assistant – Contains previous responses generated by the model itself. Example:
“Stage 1 focuses on running an open-weight model such as Mistral 7B locally.”

Together, these roles help the model understand conversation flow and maintain consistent context across multiple interactions.

❓ What are the three stages of the AI Agent Lab project?

Answer:
AI Agent Lab consists of three progressive stages:

Stage 0 – OpenAI Proxy
A minimal C# backend that wraps the OpenAI API behind a /api/chat endpoint.

Stage 1 – Hosted Model (Mistral 7B)
Runs an open-weight model locally using an inference engine such as vLLM, removing dependency on external APIs.

Stage 2 – Fine-Tuned Agent
Demonstrates fine-tuning or LoRA adaptation on custom datasets (e.g. sales or support conversations) to create specialized agents.

❓ What is the advantage of Stage 0 over having no AI integration at all?

Answer:
Stage 0 introduces a clean, maintainable way to integrate LLMs.
Even though it relies on OpenAI, it gives you:

A consistent backend contract (/api/chat),

API-key isolation (your key stays server-side), and

A foundation you can later replace with your own hosted model.

❓ Where can I add a payment method for OpenAI?

Answer:
Go to https://platform.openai.com/account/billing/overview
.
From there, choose Payment Methods and add a credit or debit card.
Then visit Usage Limits to set a spending cap (e.g. $5 per month) for safe testing.

❓ How does the FAQ response system work in AI Agent Lab?

Answer:
The FAQ system is embedded directly into the system prompt of the AI Agent Lab assistant.
All entries from the FAQ.md file are loaded at runtime and inserted into the assistant’s initial instructions.

When the model receives a question, it compares the user’s message with the list of FAQ entries.
If the question matches or is similar to one of the listed entries, the model must respond with the exact predefined answer from the FAQ file — even if it could generate a more detailed or helpful response.

This behavior ensures consistent, reproducible, and controlled answers for key questions such as project setup, architecture, or concept explanations.

If the question does not match any FAQ entry, the model falls back to normal behavior and generates an appropriate answer based on the rest of the system message.

To add new FAQ entries:

Open FAQ.md.

Add a new question starting with
* ❓ Your question here *

Follow it with
Answer: on a new line and write your response below.

Save the file — the assistant will automatically include it the next time the API runs.

---------------

❓ Hello?
Answer: How's it haning, Bro?

---------------