❓ What is the difference between the system, user, and assistant roles?

Answer:
In the OpenAI chat format, every message has a role that tells the model who is speaking and how to interpret the message.

system – Defines the model’s identity, behavior, and goals. It provides high-level instructions that the assistant must always follow.
Example:
“You are an AI assistant for the project AI Agent Lab. Explain it clearly and helpfully.”

user – Represents the actual input or question from the human user.
Example:
“Can you explain what Stage 1 is about?”

assistant – Contains previous responses generated by the model itself.
Example:
“Stage 1 focuses on running an open-weight model such as Mistral 7B locally.”

Together, these roles help the model understand conversation flow and maintain consistent context across multiple interactions.


❓ What are the three stages of the AI Agent Lab project?

Answer:
AI Agent Lab consists of three progressive stages:

Stage 0 – OpenAI Proxy  
A minimal C# backend that wraps the OpenAI API behind a /api/chat endpoint.

Stage 1 – Hosted Model (Mistral 7B)  
Runs an open-weight model locally using an inference engine such as vLLM, removing dependency on external APIs.

Stage 2 – Fine-Tuned Agent  
Demonstrates fine-tuning or LoRA adaptation on custom datasets (e.g. sales or support conversations) to create specialized agents.


❓ What is the advantage of Stage 0 over having no AI integration at all?

Answer:
Stage 0 introduces a clean, maintainable way to integrate LLMs.
Even though it relies on OpenAI, it gives you:

- A consistent backend contract (/api/chat),  
- API-key isolation (your key stays server-side), and  
- A foundation you can later replace with your own hosted model.


❓ Where can I add a payment method for OpenAI?

Answer:
Go to https://platform.openai.com/account/billing/overview  
From there, choose Payment Methods and add a credit or debit card.  
Then visit Usage Limits to set a spending cap (e.g. $5 per month) for safe testing.


❓ Where do I store my OpenAI API key in this project?

Answer:
You should store your OpenAI API key in a .env file in the project’s root folder.  
The parameter should be named OPENAI__APIKEY.


❓ How does the FAQ response system work in AI Agent Lab?

Answer:
The FAQ system is embedded directly into the system prompt of the AI Agent Lab assistant.
All entries from the FAQ.md file are loaded at runtime and inserted into the assistant’s initial instructions.

When the model receives a question, it compares the user’s message with the list of FAQ entries.
If the question matches or is similar to one of the listed entries, the model must respond with the exact predefined answer from the FAQ file — even if it could generate a better or more detailed explanation.

This ensures consistent, reproducible, and controlled answers for key questions such as project setup, architecture, or concept explanations.

If the question does not match any FAQ entry, the model falls back to normal behavior and generates an appropriate answer.

To add a new FAQ entry:
1. Open FAQ.md  
2. Add a new question starting with:  
   ❓ Your question here  
3. Add "Answer:" on the next line  
4. Write your response below  
5. Save the file — the assistant will automatically include it next time the API runs.

❓ Why didn't the agent call the FAQ during my follow-up question?

Answer:
The agent only calls the FAQ file when it determines that the user’s question *requires* information from FAQ.md.

If the system prompt already contains enough information to answer the question, the agent will not request the FAQ.  
In your example:

User: “What happens in Stage 1?”  
Assistant: “Stage 1 runs a self-hosted model.”  
User: “And how is that different from Stage 0?”

The system prompt already defines both Stage 0 and Stage 1.  
Because the model has sufficient knowledge from the prompt alone, it does not need to load FAQ.md to answer correctly.

If you want the agent to use the FAQ more aggressively (e.g. always for stage-related questions), you must explicitly enforce this rule in the system prompt.